# -*- coding: utf-8 -*-
"""
å¤šç§å¤§æ¨¡å‹è°ƒç”¨ç¤ºä¾‹ä»£ç 
æ”¯æŒçš„æ¨¡å‹ï¼šAnthropic Claudeã€OpenAIã€ç«å±±æ–¹èˆŸè±†åŒ…ã€DeepSeek
"""

import os
from model import get_completion

# =============================================================================
# 1. åŸºæœ¬è°ƒç”¨ç¤ºä¾‹
# =============================================================================

def example_basic_calls():
    """åŸºæœ¬è°ƒç”¨ç¤ºä¾‹"""
    print("=== åŸºæœ¬è°ƒç”¨ç¤ºä¾‹ ===")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¯ä»¥åœ¨ç¯å¢ƒä¸­è®¾ç½®ï¼Œè¿™é‡Œä»…ä½œæ¼”ç¤ºï¼‰
    # os.environ["ANTHROPIC_API_KEY"] = "ä½ çš„APIå¯†é’¥"
    # os.environ["OPENAI_API_KEY"] = "ä½ çš„APIå¯†é’¥"
    # os.environ["ARK_API_KEY"] = "ä½ çš„ç«å±±æ–¹èˆŸAPIå¯†é’¥"
    # os.environ["DEEPSEEK_API_KEY"] = "ä½ çš„APIå¯†é’¥"
    
    prompt = "è¯·ç”¨ä¸­æ–‡ç®€è¦ä»‹ç»äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹"
    
    # Anthropic Claude
    try:
        response = get_completion(prompt, provider="anthropic")
        print(f"Claude å›å¤: {response[:100]}...")
    except Exception as e:
        print(f"Claude è°ƒç”¨å¤±è´¥: {e}")
    
    # OpenAI
    try:
        response = get_completion(prompt, provider="openai")
        print(f"OpenAI å›å¤: {response[:100]}...")
    except Exception as e:
        print(f"OpenAI è°ƒç”¨å¤±è´¥: {e}")
    
    # ç«å±±æ–¹èˆŸè±†åŒ…
    try:
        response = get_completion(prompt, provider="volcengine")
        print(f"ç«å±±æ–¹èˆŸè±†åŒ… å›å¤: {response[:100]}...")
    except Exception as e:
        print(f"ç«å±±æ–¹èˆŸè±†åŒ… è°ƒç”¨å¤±è´¥: {e}")
    
    # DeepSeek
    try:
        response = get_completion(prompt, provider="deepseek")
        print(f"DeepSeek å›å¤: {response[:100]}...")
    except Exception as e:
        print(f"DeepSeek è°ƒç”¨å¤±è´¥: {e}")

# =============================================================================
# 2. æŒ‡å®šæ¨¡å‹è°ƒç”¨ç¤ºä¾‹
# =============================================================================

def example_specific_models():
    """æŒ‡å®šç‰¹å®šæ¨¡å‹è°ƒç”¨ç¤ºä¾‹"""
    print("\n=== æŒ‡å®šæ¨¡å‹è°ƒç”¨ç¤ºä¾‹ ===")
    
    prompt = "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—"
    
    # Claude ä¸åŒæ¨¡å‹
    models_claude = ["claude-3-haiku-20240307", "claude-3-sonnet-20240229"]
    for model in models_claude:
        try:
            response = get_completion(prompt, provider="anthropic", model=model)
            print(f"Claude {model}: {response[:50]}...")
        except Exception as e:
            print(f"Claude {model} è°ƒç”¨å¤±è´¥: {e}")
    
    # OpenAI ä¸åŒæ¨¡å‹
    models_openai = ["gpt-4o", "gpt-3.5-turbo"]
    for model in models_openai:
        try:
            response = get_completion(prompt, provider="openai", model=model)
            print(f"OpenAI {model}: {response[:50]}...")
        except Exception as e:
            print(f"OpenAI {model} è°ƒç”¨å¤±è´¥: {e}")
    
    
    # DeepSeek ä¸åŒæ¨¡å‹
    models_deepseek = ["deepseek-chat", "deepseek-reasoner"]
    for model in models_deepseek:
        try:
            response = get_completion(prompt, provider="deepseek", model=model)
            print(f"DeepSeek {model}: {response[:50]}...")
        except Exception as e:
            print(f"DeepSeek {model} è°ƒç”¨å¤±è´¥: {e}")

# =============================================================================
# 3. å‚æ•°è°ƒæ•´ç¤ºä¾‹
# =============================================================================

def example_parameter_tuning():
    """å‚æ•°è°ƒæ•´ç¤ºä¾‹"""
    print("\n=== å‚æ•°è°ƒæ•´ç¤ºä¾‹ ===")
    
    prompt = "è¯·ç”Ÿæˆä¸€ä¸ªåˆ›æ„æ•…äº‹å¼€å¤´"
    
    # ä¸åŒæ¸©åº¦è®¾ç½®
    temperatures = [0.0, 0.5, 1.0]
    for temp in temperatures:
        try:
            response = get_completion(
                prompt, 
                provider="deepseek", 
                temperature=temp,
                max_tokens=100
            )
            print(f"æ¸©åº¦ {temp}: {response[:80]}...")
        except Exception as e:
            print(f"æ¸©åº¦ {temp} è°ƒç”¨å¤±è´¥: {e}")

# =============================================================================
# 4. é”™è¯¯å¤„ç†ç¤ºä¾‹
# =============================================================================

def example_error_handling():
    """é”™è¯¯å¤„ç†ç¤ºä¾‹"""
    print("\n=== é”™è¯¯å¤„ç†ç¤ºä¾‹ ===")
    
    def safe_call(prompt, provider, model=None):
        """å®‰å…¨è°ƒç”¨å‡½æ•°"""
        try:
            response = get_completion(prompt, provider=provider, model=model)
            print(f"âœ… {provider} è°ƒç”¨æˆåŠŸ: {response[:50]}...")
            return response
        except ValueError as e:
            print(f"âŒ {provider} å‚æ•°é”™è¯¯: {e}")
        except ImportError as e:
            print(f"âŒ {provider} ä¾èµ–é”™è¯¯: {e}")
        except RuntimeError as e:
            print(f"âŒ {provider} APIè°ƒç”¨å¤±è´¥: {e}")
        except Exception as e:
            print(f"âŒ {provider} æœªçŸ¥é”™è¯¯: {e}")
        return None
    
    prompt = "ä½ å¥½ï¼Œè¯·è‡ªæˆ‘ä»‹ç»"
    
    # æµ‹è¯•å„ä¸ªæä¾›å•†
    providers = ["anthropic", "openai", "volcengine", "deepseek"]
    for provider in providers:
        safe_call(prompt, provider)

# =============================================================================
# 5. æ‰¹é‡æ¯”è¾ƒç¤ºä¾‹
# =============================================================================

def example_batch_comparison():
    """æ‰¹é‡æ¯”è¾ƒä¸åŒæ¨¡å‹çš„å›ç­”"""
    print("\n=== æ‰¹é‡æ¯”è¾ƒç¤ºä¾‹ ===")
    
    questions = [
        "ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—ï¼Ÿ",
        "å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ",
        "ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ "
    ]
    
    providers = [
        ("deepseek", "deepseek-chat"),
        ("openai", "gpt-4o"),
        ("volcengine", "ep-20241226120407-8qk9p")
    ]
    
    for question in questions:
        print(f"\nğŸ“ é—®é¢˜: {question}")
        print("-" * 50)
        
        for provider, model in providers:
            try:
                response = get_completion(
                    question, 
                    provider=provider, 
                    model=model,
                    max_tokens=150
                )
                print(f"ğŸ¤– {provider}({model}): {response[:100]}...")
            except Exception as e:
                print(f"âŒ {provider}({model}) å¤±è´¥: {e}")

# =============================================================================
# 6. é…ç½®ç®¡ç†ç¤ºä¾‹
# =============================================================================

class ModelConfig:
    """æ¨¡å‹é…ç½®ç®¡ç†ç±»"""
    
    def __init__(self):
        self.configs = {
            "åˆ›æ„å†™ä½œ": {
                "provider": "deepseek",
                "model": "deepseek-chat",
                "temperature": 0.8,
                "max_tokens": 500
            },
            "æŠ€æœ¯é—®ç­”": {
                "provider": "openai",
                "model": "gpt-4o",
                "temperature": 0.2,
                "max_tokens": 300
            },
            "ç¿»è¯‘ä»»åŠ¡": {
                "provider": "volcengine",
                "model": "ep-20241226120407-8qk9p",
                "temperature": 0.1,
                "max_tokens": 200
            }
        }
    
    def get_response(self, task_type, prompt):
        """æ ¹æ®ä»»åŠ¡ç±»å‹è·å–å“åº”"""
        if task_type not in self.configs:
            raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}")
        
        config = self.configs[task_type]
        return get_completion(prompt, **config)

def example_config_management():
    """é…ç½®ç®¡ç†ç¤ºä¾‹"""
    print("\n=== é…ç½®ç®¡ç†ç¤ºä¾‹ ===")
    
    config_manager = ModelConfig()
    
    tasks = [
        ("åˆ›æ„å†™ä½œ", "å†™ä¸€ä¸ªå…³äºæœºå™¨äººçš„ç§‘å¹»æ•…äº‹å¼€å¤´"),
        ("æŠ€æœ¯é—®ç­”", "Pythonä¸­çš„è£…é¥°å™¨æ˜¯ä»€ä¹ˆï¼Ÿ"),
        ("ç¿»è¯‘ä»»åŠ¡", "Please translate 'Hello World' to Chinese")
    ]
    
    for task_type, prompt in tasks:
        try:
            response = config_manager.get_response(task_type, prompt)
            print(f"ğŸ“‹ {task_type}: {response[:80]}...")
        except Exception as e:
            print(f"âŒ {task_type} å¤±è´¥: {e}")

# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================

if __name__ == "__main__":
    print("ğŸš€ å¤šç§å¤§æ¨¡å‹è°ƒç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    example_basic_calls()
    example_specific_models()
    example_parameter_tuning()
    example_error_handling()
    example_batch_comparison()
    example_config_management()
    
    print("\nâœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. éœ€è¦å…ˆè®¾ç½®ç›¸åº”çš„APIå¯†é’¥ç¯å¢ƒå˜é‡:")
    print("   - ANTHROPIC_API_KEY (Claude)")
    print("   - OPENAI_API_KEY (OpenAI)")
    print("   - ARK_API_KEY (ç«å±±æ–¹èˆŸ)")
    print("   - DEEPSEEK_API_KEY (DeepSeek)")
    print("2. ç«å±±æ–¹èˆŸéœ€è¦ä½¿ç”¨endpoint IDä½œä¸ºmodelå‚æ•°")
    print("3. ç«å±±æ–¹èˆŸéœ€è¦å®‰è£…: pip install volcengine-python-sdk[ark]")
    print("4. å„ä¸ªæ¨¡å‹çš„å…·ä½“åç§°è¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£")
    print("5. æ ¹æ®éœ€è¦è°ƒæ•´temperatureå’Œmax_tokenså‚æ•°")