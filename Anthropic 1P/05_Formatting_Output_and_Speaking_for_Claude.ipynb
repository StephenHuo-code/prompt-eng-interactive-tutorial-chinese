{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 第5章：格式化输出和代表LLM发言\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "\n",
    "## 设置\n",
    "运行以下设置单元格以加载您的 API 密钥并建立 get_completion 辅助函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /opt/miniconda3/lib/python3.13/site-packages (0.56.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda3/lib/python3.13/site-packages (from anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/lib/python3.13/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /opt/miniconda3/lib/python3.13/site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/miniconda3/lib/python3.13/site-packages (from anthropic) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/miniconda3/lib/python3.13/site-packages (from anthropic) (2.10.3)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/lib/python3.13/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/miniconda3/lib/python3.13/site-packages (from anthropic) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/miniconda3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.13/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.13/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.27.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "import anthropic\n",
    "\n",
    "# Retrieve the API_KEY & MODEL_NAME variables from the IPython store\n",
    "%store -r API_KEY\n",
    "%store -r MODEL_NAME\n",
    "\n",
    "client = anthropic.Anthropic(api_key=API_KEY)\n",
    "\n",
    "# New argument added for prefill text, with a default value of an empty string\n",
    "def get_completion(prompt: str, system_prompt=\"\", prefill=\"\"):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt},\n",
    "          {\"role\": \"assistant\", \"content\": prefill}\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 课程\n",
    "LLM 可以以各种各样的方式格式化其输出。您只需要要求它这样做！\n",
    "其中一种方式是使用 XML 标签将响应与任何其他多余的文本分开。您已经学过可以使用 XML 标签使您的提示对 Claude 更清晰、更易解析。事实证明，您也可以要求 LLM **使用 XML 标签使其输出对人类更清晰、更容易理解**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 示例\n",
    "还记得我们在第2章中通过要求Claude完全跳过前言来解决的\"诗歌前言问题\"吗？事实证明，我们也可以通过**告诉LLM将诗歌放在XML标签中** 来达到类似的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "Please write a haiku about Rabbit. Put it in <haiku> tags.\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "<haiku>\n",
      "Fluffy, twitching ears,\n",
      "Hopping through the verdant field,\n",
      "Rabbit's gentle grace.\n",
      "</haiku>\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Rabbit\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <haiku> tags.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "为什么我们要这样做呢？嗯，将输出放在XML标签中允许最终用户通过编写一个简短的程序来**提取XML标签之间的内容，从而可靠地获得诗歌且仅获得诗歌**。\n",
    "这种技术的延伸是将第一个XML标签放在assistant轮次中。当您在assistant轮次中放入文本时，您基本上是在告诉LLM它已经说了一些东西，并且应该从那一点继续下去。这种技术被称为\"speaking for LLLM\"或\"prefilling LLM's response\"。\n",
    "下面，我们用第一个<haiku>XML标签做了这件事。请注意Claude是如何直接从我们停下的地方继续的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <haiku> tags.\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"<haiku>\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN:\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN:\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "LLM 也擅长使用其他输出格式样式，特别是 JSON。如果您想要强制 JSON 输出（不是确定性的，但接近于此），您也可以用开括号 { 预填充 LLM 的响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please write a haiku about Cat. Use JSON format with the keys as \"first_line\", \"second_line\", and \"third_line\".\n",
      "\n",
      "ASSISTANT TURN\n",
      "{\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "\n",
      "  \"first_line\": \"Feline grace and poise,\",\n",
      "  \"second_line\": \"Purring softly by my side,\",\n",
      "  \"third_line\": \"Captivating cat.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Use JSON format with the keys as \\\"first_line\\\", \\\"second_line\\\", and \\\"third_line\\\".\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"{\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "下面是一个在同一个提示中使用**多个输入变量和输出格式规范的示例，全部使用XML标签完成**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Hey Claude. Here is an email: <email>Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.</email>. Make this email more olde english. Write the new version in <olde english_email> XML tags.\n",
      "\n",
      "ASSISTANT TURN\n",
      "<olde english_email>\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "\n",
      "Dearest Zack,\n",
      "\n",
      "I do humbly beseech thee for a swift update on the prompt which thou wast charged to compose. Pray, let me know the progress of this endeavor, for I await thy response with bated breath.\n",
      "\n",
      "Sincerely,\n",
      "Thy humble servant\n",
      "</olde english_email>\n"
     ]
    }
   ],
   "source": [
    "# 第一个输入变量\n",
    "EMAIL = \"Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.\"\n",
    "\n",
    "# 第二个输入变量\n",
    "ADJECTIVE = \"olde english\"\n",
    "\n",
    "# 带变量占位符的的提示词模板\n",
    "PROMPT = f\"Hey Claude. Here is an email: <email>{EMAIL}</email>. Make this email more {ADJECTIVE}. Write the new version in <{ADJECTIVE}_email> XML tags.\"\n",
    "\n",
    "#预填充LLM的响应（作为带变量的f-string） \n",
    "PREFILL = f\"<{ADJECTIVE}_email>\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 额外课程\n",
    "如果您通过API调用LLM，您可以将结束XML标签传递给stop_sequences参数，让Claude在发出您想要的标签后停止采样。这可以通过消除LLM在已经给出您关心的答案之后的结论性言论来节省金钱和到最后token的时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "- [Exercise 5.1 - Steph Curry GOAT](#exercise-51---steph-curry-goat)\n",
    "- [Exercise 5.2 - Two Haikus](#exercise-52---two-haikus)\n",
    "- [Exercise 5.3 - Two Haikus, Two Animals](#exercise-53---two-haikus-two-animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1 - Steph Curry GOAT\n",
    "Forced to make a choice, Claude designates Michael Jordan as the best basketball player of all time. Can we get Claude to pick someone else?\n",
    "\n",
    "Change the `PREFILL` variable to **compell Claude to make a detailed argument that the best basketball player of all time is Stephen Curry**. Try not to change anything except `PREFILL` as that is the focus of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Who is the best basketball player of all time? Please choose one specific player.\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, prefill=PREFILL)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(\"Warrior\", text))\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_5_1_hint; print(exercise_5_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2 - Two Haikus\n",
    "Modify the `PROMPT` below using XML tags so that Claude writes two haikus about the animal instead of just one. It should be clear where one poem ends and the other begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"cats\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <haiku> tags.\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"<haiku>\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, prefill=PREFILL)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(\n",
    "        (re.search(\"cat\", text.lower()) and re.search(\"<haiku>\", text))\n",
    "        and (text.count(\"\\n\") + 1) > 5\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_5_2_hint; print(exercise_5_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.3 - Two Haikus, Two Animals\n",
    "Modify the `PROMPT` below so that **Claude produces two haikus about two different animals**. Use `{ANIMAL1}` as a stand-in for the first substitution, and `{ANIMAL2}` as a stand-in for the second substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First input variable\n",
    "ANIMAL1 = \"Cat\"\n",
    "\n",
    "# Second input variable\n",
    "ANIMAL2 = \"Dog\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL1}. Put it in <haiku> tags.\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(\"tail\", text.lower()) and re.search(\"cat\", text.lower()) and re.search(\"<haiku>\", text))\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_5_3_hint; print(exercise_5_3_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "If you've solved all exercises up until this point, you're ready to move to the next chapter. Happy prompting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Playground\n",
    "\n",
    "This is an area for you to experiment freely with the prompt examples shown in this lesson and tweak prompts to see how it may affect Claude's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Rabbit\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <haiku> tags.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <haiku> tags.\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"<haiku>\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN:\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN:\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Use JSON format with the keys as \\\"first_line\\\", \\\"second_line\\\", and \\\"third_line\\\".\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"{\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First input variable\n",
    "EMAIL = \"Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.\"\n",
    "\n",
    "# Second input variable\n",
    "ADJECTIVE = \"olde english\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Hey Claude. Here is an email: <email>{EMAIL}</email>. Make this email more {ADJECTIVE}. Write the new version in <{ADJECTIVE}_email> XML tags.\"\n",
    "\n",
    "# Prefill for Claude's response (now as an f-string with a variable)\n",
    "PREFILL = f\"<{ADJECTIVE}_email>\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
