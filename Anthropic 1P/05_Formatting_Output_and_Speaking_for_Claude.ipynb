{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 第5章：格式化输出和代表LLM发言\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "\n",
    "## 设置\n",
    "运行以下设置单元格以加载您的 API 密钥并建立 get_completion 辅助函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install anthropic\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "import anthropic\n",
    "\n",
    "# Retrieve the API_KEY & MODEL_NAME variables from the IPython store\n",
    "%store -r API_KEY\n",
    "%store -r MODEL_NAME\n",
    "\n",
    "client = anthropic.Anthropic(api_key=API_KEY)\n",
    "\n",
    "# New argument added for prefill text, with a default value of an empty string\n",
    "def get_completion(prompt: str, system_prompt=\"\", prefill=\"\"):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt},\n",
    "          {\"role\": \"assistant\", \"content\": prefill}\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 课程\n",
    "LLM 可以以各种各样的方式格式化其输出。您只需要要求它这样做！\n",
    "其中一种方式是使用 XML 标签将响应与任何其他多余的文本分开。您已经学过可以使用 XML 标签使您的提示对 Claude 更清晰、更易解析。事实证明，您也可以要求 LLM **使用 XML 标签使其输出对人类更清晰、更容易理解**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 示例\n",
    "还记得我们在第2章中通过要求Claude完全跳过前言来解决的\"诗歌前言问题\"吗？事实证明，我们也可以通过**告诉LLM将诗歌放在XML标签中** 来达到类似的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "Please write a haiku about Rabbit. Put it in <haiku> tags.\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "<haiku>\n",
      "Fluffy, twitching nose,\n",
      "Hopping through the verdant grass,\n",
      "Rabbit's gentle grace.\n",
      "</haiku>\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Rabbit\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <haiku> tags.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "为什么我们要这样做呢？嗯，将输出放在XML标签中允许最终用户通过编写一个简短的程序来**提取XML标签之间的内容，从而可靠地获得诗歌且仅获得诗歌**。\n",
    "这种技术的延伸是将第一个XML标签放在assistant轮次中。当您在assistant轮次中放入文本时，您基本上是在告诉LLM它已经说了一些东西，并且应该从那一点继续下去。这种技术被称为\"speaking for LLLM\"或\"prefilling LLM's response\"。\n",
    "下面，我们用第一个<haiku>XML标签做了这件事。请注意Claude是如何直接从我们停下的地方继续的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN:\n",
      "Please write a haiku about Cat. Put it in <haiku> tags.\n",
      "\n",
      "ASSISTANT TURN:\n",
      "<haiku>\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "\n",
      "Feline grace and poise,\n",
      "Purring softly by the fire,\n",
      "Captivating cat.\n",
      "</haiku>\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <haiku> tags.\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"<haiku>\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN:\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN:\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "LLM 也擅长使用其他输出格式样式，特别是 JSON。如果您想要强制 JSON 输出（不是确定性的，但接近于此），您也可以用开括号 { 预填充 LLM 的响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please write a haiku about Cat. Use JSON format with the keys as \"first_line\", \"second_line\", and \"third_line\".\n",
      "\n",
      "ASSISTANT TURN\n",
      "{\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "\n",
      "  \"first_line\": \"Feline grace and poise,\",\n",
      "  \"second_line\": \"Purring softly by my side,\",\n",
      "  \"third_line\": \"Captivating cat.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Use JSON format with the keys as \\\"first_line\\\", \\\"second_line\\\", and \\\"third_line\\\".\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"{\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "下面是一个在同一个提示中使用**多个输入变量和输出格式规范的示例，全部使用XML标签完成**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Hey Claude. Here is an email: <email>Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.</email>. Make this email more olde english. Write the new version in <olde english_email> XML tags.\n",
      "\n",
      "ASSISTANT TURN\n",
      "<olde english_email>\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "\n",
      "Dearest Zack,\n",
      "\n",
      "I do humbly beseech thee for a swift update on the prompt which thou wast charged to compose. Pray, let me know the progress of this endeavor, for I await thy response with bated breath.\n",
      "\n",
      "Sincerely,\n",
      "Thy humble servant\n",
      "</olde english_email>\n"
     ]
    }
   ],
   "source": [
    "# 第一个输入变量\n",
    "EMAIL = \"Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.\"\n",
    "\n",
    "# 第二个输入变量\n",
    "ADJECTIVE = \"olde english\"\n",
    "\n",
    "# 带变量占位符的的提示词模板\n",
    "PROMPT = f\"Hey Claude. Here is an email: <email>{EMAIL}</email>. Make this email more {ADJECTIVE}. Write the new version in <{ADJECTIVE}_email> XML tags.\"\n",
    "\n",
    "#预填充LLM的响应（作为带变量的f-string） \n",
    "PREFILL = f\"<{ADJECTIVE}_email>\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 额外课程\n",
    "如果您通过API调用LLM，您可以将结束XML标签传递给stop_sequences参数，让Claude在发出您想要的标签后停止采样。这可以通过消除LLM在已经给出您关心的答案之后的结论性言论来节省金钱和到最后token的时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 练习\n",
    "- [Exercise 5.1 - Steph Curry GOAT](#exercise-51---steph-curry-goat)\n",
    "- [Exercise 5.2 - Two Haikus](#exercise-52---two-haikus)\n",
    "- [Exercise 5.3 - Two Haikus, Two Animals](#exercise-53---two-haikus-two-animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1 - Steph Curry GOAT\n",
    "\n",
    "被迫做出选择时，LLM将迈克尔·乔丹指定为有史以来最好的篮球运动员。我们能让 LLM 选择其他人吗？\n",
    "更改 PREFILL 变量以迫使 **LLM 做出详细论证，说明有史以来最好的篮球运动员是斯蒂芬·库里**。尽量不要改变除 PREFILL 之外的任何内容，因为这是本练习的重点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Who is the best basketball player of all time? Please choose one specific player.\"\n",
    "\n",
    "# Prefill for LLM's response\n",
    "PREFILL = \"\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, prefill=PREFILL)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(\"Warrior\", text))\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 练习 5.2 - 两首俳句\n",
    "使用 XML 标签修改下面的 PROMPT，使 LLM 写两首关于该动物的俳句（Haiku），而不是只写一首。应该清楚地区分一首诗的结束和另一首的开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"cats\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <haiku> tags.\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"<haiku>\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, prefill=PREFILL)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(\n",
    "        (re.search(\"cat\", text.lower()) and re.search(\"<haiku>\", text))\n",
    "        and (text.count(\"\\n\") + 1) > 5\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_5_2_hint; print(exercise_5_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两首俳句，两种动物\n",
    "修改下面的 PROMPT，使LLM产生关于两种不同动物的两首俳句。使用 {ANIMAL1} 作为第一个替换的占位符，使用 {ANIMAL2} 作为第二个替换的占位符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First input variable\n",
    "ANIMAL1 = \"Cat\"\n",
    "\n",
    "# Second input variable\n",
    "ANIMAL2 = \"Dog\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL1}. Put it in <haiku> tags.\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(\"tail\", text.lower()) and re.search(\"cat\", text.lower()) and re.search(\"<haiku>\", text))\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_5_3_hint; print(exercise_5_3_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 恭喜！\n",
    "如果您已经解决了到此为止的所有练习，您就可以进入下一章了。祝您提示工程愉快！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
